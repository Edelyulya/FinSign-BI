# etl/wb_loader.py
import argparse
import json
import time
from datetime import datetime, date
from pathlib import Path
from typing import Dict, List, Any

import pandas as pd
import requests
from sqlalchemy import create_engine, text

WB_URL_REPORT = "https://statistics-api.wildberries.ru/api/v1/supplier/reportDetailByPeriod"
DEFAULT_LIMIT = 100000  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω—ã–π –ª–∏–º–∏—Ç –Ω–∞ –≤—ã–∑–æ–≤

# ---------- utils ----------

def load_cfg() -> Dict[str, Any]:
    """–ß–∏—Ç–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥ –∏–∑ config.json –≤ –∫–æ—Ä–Ω–µ —Ä–µ–ø–æ."""
    ROOT = Path(__file__).resolve().parents[1]
    cfg_path = ROOT / "config.json"
    with cfg_path.open("r", encoding="utf-8") as f:
        return json.load(f)

def make_engine(cfg: Dict[str, Any]):
    db = cfg["db"]
    conn = (
        f"postgresql+psycopg://{db['user']}:{db['password']}"
        f"@{db['host']}:{db['port']}/{db['database']}"
    )
    return create_engine(conn, pool_pre_ping=True)

def coalesce(*vals, default=None):
    for v in vals:
        if v not in (None, "", "null"):
            return v
    return default

def parse_date(s: str) -> date | None:
    if not s:
        return None
    # WB –º–æ–∂–µ—Ç –ø—Ä–∏—Å–ª–∞—Ç—å "2025-10-29T11:22:33" –∏–ª–∏ "2025-10-29 11:22:33"
    s = s.replace("T", " ")
    try:
        return datetime.fromisoformat(s).date()
    except Exception:
        try:
            return datetime.strptime(s, "%Y-%m-%d %H:%M:%S").date()
        except Exception:
            return None

# ---------- WB API ----------

def fetch_report_batch(token: str, since: str, until: str, rrdid: int) -> List[Dict[str, Any]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–Ω—É "—Å—Ç—Ä–∞–Ω–∏—Ü—É" –æ—Ç—á—ë—Ç–∞ –ø—Ä–æ–¥–∞–∂ –∑–∞ –ø–µ—Ä–∏–æ–¥.
    –ü–∞–≥–∏–Ω–∞—Ü–∏—è —á–µ—Ä–µ–∑ rrdid (0 -> —Å–ª–µ–¥—É—é—â–∏–π rrdid –∏–∑ –æ—Ç–≤–µ—Ç–∞).
    """
    headers = {"Authorization": token}
    payload = {
        "dateFrom": since,
        "dateTo": until,
        "rrdid": rrdid,
        "limit": DEFAULT_LIMIT,
    }
    r = requests.post(WB_URL_REPORT, headers=headers, json=payload, timeout=60)
    if r.status_code != 200:
        raise RuntimeError(f"WB API HTTP {r.status_code}: {r.text}")
    # –û—Ç–≤–µ—Ç ‚Äî JSON-–º–∞—Å—Å–∏–≤ —Å—Ç—Ä–æ–∫ –æ—Ç—á—ë—Ç–∞
    return r.json()

def fetch_report_all(token: str, since: str, until: str) -> List[Dict[str, Any]]:
    """–ó–∞–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç—á—ë—Ç–∞, –ø–æ–∫–∞ –Ω–µ –∫–æ–Ω—á–∞—Ç—Å—è –¥–∞–Ω–Ω—ã–µ."""
    results: List[Dict[str, Any]] = []
    rrdid = 0
    page = 0
    while True:
        page += 1
        batch = fetch_report_batch(token, since, until, rrdid)
        if not batch:
            break
        results.extend(batch)
        # rrdid ‚Äî —ç—Ç–æ id –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–∏—Å–∏; –±–µ—Ä—ë–º –º–∞–∫—Å–∏–º—É–º –∏–∑ –ø–∞—Ä—Ç–∏–∏
        rrdid = max(item.get("rrd_id") or item.get("rrdid") or 0 for item in batch)
        # —á—É—Ç—å-—á—É—Ç—å –ø–∞—É–∑—ã, –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
        time.sleep(0.2)
    return results

# ---------- transform & load ----------

def normalize_to_df(items: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∞—à–µ–π "—Å—ã—Ä–æ–π" —Ñ–æ—Ä–º–µ.
    –ü–æ–ª—è –≤ WB –º–æ–≥—É—Ç –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–≤–∏–∑–∏—è—Ö –æ—Ç—á—ë—Ç–∞,
    –ø–æ—ç—Ç–æ–º—É –±–µ—Ä—ë–º —Å –∑–∞–ø–∞—Å–æ–º: sale_dt/saleDt, supplierArticle/sa_article/sa_name –∏ —Ç.–ø.
    """
    rows = []
    for it in items:
        sale_dt = coalesce(it.get("sale_dt"), it.get("saleDt"), it.get("date"))
        dt = parse_date(sale_dt)

        sku = coalesce(
            it.get("supplierArticle"),
            it.get("sa_article"),
            it.get("sa_name"),
            it.get("nm_id"),
            it.get("barcode"),
            default="UNKNOWN",
        )

        region = coalesce(it.get("regionName"), it.get("region_name"))

        qty = coalesce(it.get("quantity"), it.get("sale_qty"), 0) or 0
        # —Ü–µ–Ω–∞/–≤—ã—Ä—É—á–∫–∞: retail_price ‚Äî —Ü–µ–Ω–∞, retail_amount ‚Äî —Å—É–º–º–∞ –ø–æ —Å—Ç—Ä–æ–∫–µ
        price = coalesce(it.get("retail_price"), it.get("price"), 0) or 0
        # –í raw –º—ã —Ö—Ä–∞–Ω–∏–º qty/price, –¥–ª—è mart –ø–æ—Å—á–∏—Ç–∞–µ–º revenue = qty*price
        rows.append(
            {
                "date": dt,
                "sku": str(sku) if sku is not None else "UNKNOWN",
                "region": region,
                "quantity": float(qty),
                "price": float(price),
                "payload": it,
            }
        )
    df = pd.DataFrame(rows, columns=["date", "sku", "region", "quantity", "price", "payload"])
    # —É–±–µ—Ä—ë–º —è–≤–Ω—ã–π –º—É—Å–æ—Ä
    if not df.empty:
        df = df[df["date"].notna()]
    return df

def upsert_raw_wb(engine, df: pd.DataFrame) -> int:
    """
    –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: –æ—á–∏—â–∞–µ–º –æ–∫–Ω–æ –∏ –∫–ª–∞–¥—ë–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ (idempotent –¥–ª—è –ø–µ—Ä–∏–æ–¥–∞).
    –¢—É—Ç –º—ã —É–¥–∞–ª–∏–º —Å—Ç–∞—Ä—ã–µ WB-–∑–∞–ø–∏—Å–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥ –∏ –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º.
    """
    if df.empty:
        return 0
    d_min = df["date"].min()
    d_max = df["date"].max()
    with engine.begin() as conn:
        conn.execute(
            text("DELETE FROM raw.wb_sales WHERE date BETWEEN :dmin AND :dmax"),
            {"dmin": d_min, "dmax": d_max},
        )
    df.to_sql("wb_sales", engine, schema="raw", if_exists="append", index=False, method="multi", chunksize=1000)
    return len(df)

def log_etl(engine, status: str, source: str, rows: int, meta: Dict[str, Any] | None = None):
    """
    –ü–∏—à–µ–º –ª–æ–≥, –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–∞–±–ª–∏—Ü–∞ raw.etl_log (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞).
    """
    try:
        with engine.begin() as conn:
            conn.execute(
                text("""
                    INSERT INTO raw.etl_log(run_at, source, status, rows, meta)
                    VALUES (now(), :source, :status, :rows, CAST(:meta AS jsonb))
                """),
                {"source": source, "status": status, "rows": rows, "meta": json.dumps(meta or {})},
            )
    except Exception:
        # —Ç–∏—Ö–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º, –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –µ—â—ë –Ω–µ—Ç
        pass

# ---------- CLI ----------

def run():
    parser = argparse.ArgumentParser(description="WB ‚Üí raw.wb_sales loader")
    parser.add_argument("--since", required=True, help="–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD)")
    parser.add_argument("--until", required=True, help="–î–∞—Ç–∞ –∫–æ–Ω—Ü–∞ –ø–µ—Ä–∏–æ–¥–∞ (YYYY-MM-DD)")
    parser.add_argument("--dry-run", action="store_true", help="–ù–µ –ø–∏—Å–∞—Ç—å –≤ –ë–î, —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –æ–±—ä—ë–º")
    args = parser.parse_args()

    cfg = load_cfg()
    token = cfg["wb_api"]["token"]
    engine = make_engine(cfg)

    print("üöÄ –ó–∞–ø—É—Å–∫ ETL –∏–∑ WB API...")
    items = fetch_report_all(token, args.since, args.until)
    print(f"‚Ä¢ –ü–æ–ª—É—á–µ–Ω–æ —Å—Ç—Ä–æ–∫: {len(items)}")

    df = normalize_to_df(items)
    print(f"‚Ä¢ –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ —Å—Ç—Ä–æ–∫: {len(df)}")

    if args.dry_run:
        print("‚ÑπÔ∏è DRY-RUN: –∑–∞–ø–∏—Å—å –≤ –ë–î –ø—Ä–æ–ø—É—â–µ–Ω–∞.")
        return

    written = upsert_raw_wb(engine, df)
    log_etl(engine, status="ok", source="wb", rows=written, meta={"since": args.since, "until": args.until})
    print(f"‚úÖ –ó–∞–ø–∏—Å–∞–Ω–æ –≤ raw.wb_sales: {written}")

if __name__ == "__main__":
    run()
