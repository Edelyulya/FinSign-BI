from sqlalchemy import text

def bootstrap_raw(engine):
    ddl = """
    CREATE SCHEMA IF NOT EXISTS raw;

    CREATE TABLE IF NOT EXISTS raw.etl_log (
      id bigserial PRIMARY KEY,
      source text NOT NULL,
      endpoint text NOT NULL,
      started_at timestamptz NOT NULL DEFAULT now(),
      finished_at timestamptz,
      status text NOT NULL DEFAULT 'running',
      rows_loaded integer DEFAULT 0,
      message text
    );

    CREATE TABLE IF NOT EXISTS raw.ozon_stock_raw (
      id bigserial PRIMARY KEY,
      loaded_at timestamptz NOT NULL DEFAULT now(),
      payload jsonb NOT NULL
    );

    CREATE TABLE IF NOT EXISTS raw.ozon_stock (
      loaded_at timestamptz NOT NULL DEFAULT now(),
      date date,
      warehouse_name text,
      region text,
      product_id text,
      sku text,
      item_name text,
      quantity numeric,
      reserved numeric,
      price numeric
    );
    """
    with engine.begin() as conn:
        conn.execute(text(ddl))

import argparse
import json
import time
from datetime import date
from pathlib import Path
from typing import Any, Dict, List, Tuple, Union

import pandas as pd
import requests
from sqlalchemy import create_engine, text


ROOT = Path(__file__).resolve().parents[1]
CONFIG_PATH = ROOT / "config.json"

# ---------- helpers ----------
def load_config() -> Dict[str, Any]:
    with CONFIG_PATH.open("r", encoding="utf-8") as f:
        return json.load(f)

def make_engine(cfg: Dict[str, Any]):
    db = cfg["db"]
    conn_str = (
        f"postgresql+psycopg://{db['user']}:{db['password']}"
        f"@{db['host']}:{db['port']}/{db['database']}"
    )
    return create_engine(conn_str, pool_pre_ping=True)

def backoff(retry: int) -> None:
    delay = min(2 ** retry, 30)  # 1,2,4,8,16,30...
    time.sleep(delay)

# ---------- Ozon client ----------
OZON_URL_STOCK = "https://api-seller.ozon.ru/v2/analytics/stock_on_warehouses"

def ozon_headers(cfg: Dict[str, Any]) -> Dict[str, str]:
    oz = cfg["ozon_api"]
    return {"Client-Id": oz["client_id"], "Api-Key": oz["api_key"]}

def post_with_retries(url: str, headers: Dict[str, str], payload: Dict[str, Any]) -> Dict[str, Any]:
    max_retries = 5
    for attempt in range(max_retries):
        try:
            resp = requests.post(url, json=payload, headers=headers, timeout=60)
            if resp.status_code == 200:
                return resp.json()
            else:
                msg = f"Ozon API HTTP {resp.status_code}: {resp.text[:300]}"
                # 5xx ‚Äî –ø—Ä–æ–±—É–µ–º —Ä–µ—Ç—Ä–∞–∏, 4xx ‚Äî —Å—Ä–∞–∑—É –ø–∞–¥–∞–µ–º (–æ–±—ã—á–Ω–æ –Ω–µ–≤–µ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å/–∫–ª—é—á–∏)
                if 500 <= resp.status_code < 600:
                    backoff(attempt)
                    continue
                raise RuntimeError(msg)
        except requests.RequestException as e:
            if attempt == max_retries - 1:
                raise
            backoff(attempt)
    # —Å—é–¥–∞ –Ω–µ –¥–æ–π–¥—ë–º
    return {}

def extract_items(data: Dict[str, Any]) -> List[Dict[str, Any]]:
    """–û—Ç–≤–µ—Ç—ã Ozon –±—ã–≤–∞—é—Ç –∫–∞–∫ –º–∞—Å—Å–∏–≤, —Ç–∞–∫ –∏ –æ–±—ä–µ–∫—Ç c –ø–æ–ª—è–º–∏.
       –ü—Ä–æ–±—É–µ–º –≤—ã—Ç–∞—â–∏—Ç—å –º–∞—Å—Å–∏–≤ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ."""
    if not isinstance(data, dict):
        return []
    res = data.get("result", data)
    if isinstance(res, list):
        return res
    if isinstance(res, dict):
        # —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
        for key in ("items", "stocks", "data", "rows"):
            if isinstance(res.get(key), list):
                return res[key]
    return []

def fetch_all_ozon_stock(cfg: Dict[str, Any], page_limit: int = 1000) -> List[Dict[str, Any]]:
    """–ü–∞–≥–∏–Ω–∞—Ü–∏—è –ø–æ limit/offset –¥–æ –≤—ã—á–µ—Ä–ø—ã–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö."""
    headers = ozon_headers(cfg)
    all_items: List[Dict[str, Any]] = []
    offset = 0

    while True:
        payload = {
            "limit": page_limit,   # –≤–∞–∂–Ω–æ: 1..1000
            "offset": offset
            # —Å—é–¥–∞ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã, –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è
        }
        data = post_with_retries(OZON_URL_STOCK, headers, payload)
        batch = extract_items(data)
        batch_count = len(batch)
        print(f"‚Ä¢ batch @ offset={offset}: {batch_count}")
        if batch_count == 0:
            break
        all_items.extend(batch)
        if batch_count < page_limit:
            break
        offset += page_limit

    return all_items

# ---------- normalization ----------
def normalize_stock(items: List[Dict[str, Any]]) -> pd.DataFrame:
    if not items:
        return pd.DataFrame()

    df = pd.json_normalize(items)

    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
    for col in [
        "date", "updated_at", "warehouse_name", "region",
        "product_id", "sku", "item_name", "quantity", "reserved", "price"
    ]:
        if col not in df.columns:
            df[col] = None

    # –¥–∞—Ç–∞
    if "date" in df:
        df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.date
    if df["date"].isna().all():
        df["date"] = pd.to_datetime(df.get("updated_at"), errors="coerce").dt.date
    if df["date"].isna().all():
        df["date"] = date.today()

    # —á–∏—Å–ª–æ–≤—ã–µ
    for num_col in ["quantity", "reserved", "price"]:
        df[num_col] = pd.to_numeric(df[num_col], errors="coerce").fillna(0)

    out = df[
        ["date", "warehouse_name", "region", "product_id", "sku", "item_name", "quantity", "reserved", "price"]
    ].copy()

    # —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–æ–≤
    out["warehouse_name"] = out["warehouse_name"].astype("string")
    out["region"] = out["region"].astype("string")
    out["product_id"] = out["product_id"].astype("string")
    out["sku"] = out["sku"].astype("string")
    out["item_name"] = out["item_name"].astype("string")

    return out

# ---------- persistence ----------
def start_log(engine, source: str, endpoint: str) -> int:
    with engine.begin() as conn:
        res = conn.execute(
            text("INSERT INTO raw.etl_log (source, endpoint) VALUES (:s,:e) RETURNING id"),
            {"s": source, "e": endpoint},
        )
        return res.scalar_one()

def finish_log(engine, log_id: int, status: str, rows: int, message: str = None):
    with engine.begin() as conn:
        conn.execute(
            text("""
                UPDATE raw.etl_log
                   SET finished_at = now(),
                       status = :st,
                       rows_loaded = :rows,
                       message = :msg
                 WHERE id = :id
            """),
            {"st": status, "rows": rows, "msg": message, "id": log_id},
        )

def persist_raw(engine, payload_list: List[Dict[str, Any]]):
    if not payload_list:
        return 0
    df_raw = pd.DataFrame({"payload": payload_list})
    df_raw.to_sql("ozon_stock_raw", engine, schema="raw", if_exists="append", index=False)
    return len(df_raw)

def persist_normalized(engine, df_norm: pd.DataFrame):
    if df_norm.empty:
        return 0
    df_norm.to_sql("ozon_stock", engine, schema="raw", if_exists="append", index=False)
    return len(df_norm)

from sqlalchemy import text

def bootstrap_mart(engine):
    """–°–æ–∑–¥–∞—ë—Ç —Å—Ö–µ–º—É mart –∏ —Ç–∞–±–ª–∏—Ü—É fact_sales (–µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç) + –∏–Ω–¥–µ–∫—Å—ã –∏ –≤—å—é."""
    ddl = """
CREATE SCHEMA IF NOT EXISTS mart;

CREATE TABLE IF NOT EXISTS mart.fact_sales (
    date        date            NOT NULL,
    marketplace text            NOT NULL DEFAULT 'ozon',
    sku         text            NOT NULL,
    region      text            NOT NULL DEFAULT '',
    revenue     numeric(18,2)   NOT NULL DEFAULT 0,
    cost        numeric(18,2)   NOT NULL DEFAULT 0,
    profit      numeric(18,2)   GENERATED ALWAYS AS (revenue - cost) STORED,
    PRIMARY KEY (date, marketplace, sku, region)
);

CREATE INDEX IF NOT EXISTS ix_fact_sales_date        ON mart.fact_sales(date);
CREATE INDEX IF NOT EXISTS ix_fact_sales_marketplace ON mart.fact_sales(marketplace);
CREATE INDEX IF NOT EXISTS ix_fact_sales_sku         ON mart.fact_sales(sku);
CREATE INDEX IF NOT EXISTS ix_fact_sales_region      ON mart.fact_sales(region);

CREATE OR REPLACE VIEW mart.vw_kpi AS
SELECT
    date,
    marketplace,
    SUM(revenue) AS revenue,
    SUM(cost)    AS cost,
    SUM(profit)  AS profit
FROM mart.fact_sales
GROUP BY 1,2;
"""

    with engine.begin() as conn:
        conn.execute(text(ddl))

def rebuild_mart_from_raw(engine):
    """–ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∞ mart.fact_sales –Ω–∞–ø—Ä—è–º—É—é –∏–∑ raw.ozon_stock (–±–µ–∑ TEMP-—Ç–∞–±–ª–∏—Ü)."""
    sql = """
    TRUNCATE TABLE mart.fact_sales;

    INSERT INTO mart.fact_sales (date, marketplace, sku, region, revenue, cost)
    SELECT
        COALESCE(date, CURRENT_DATE)::date                AS date,
        'ozon'::text                                      AS marketplace,
        COALESCE(sku, 'UNKNOWN')::text                    AS sku,
        COALESCE(NULLIF(region, ''), '')::text            AS region,
        (COALESCE(quantity, 0)::numeric
         * COALESCE(price,    0)::numeric)               AS revenue,
        0::numeric(18,2)                                  AS cost
    FROM raw.ozon_stock;
    """
    with engine.begin() as conn:
        conn.execute(text(sql))

# ---------- CLI ----------
def run():
    parser = argparse.ArgumentParser(description="ETL: Ozon stock_on_warehouses ‚Üí raw")
    parser.add_argument("--dry-run", action="store_true", help="–ù–µ –ø–∏—Å–∞—Ç—å –≤ –ë–î, —Ç–æ–ª—å–∫–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å –∏ –ø–æ–∫–∞–∑–∞—Ç—å —Å—á–µ—Ç—á–∏–∫")
    args = parser.parse_args()

    cfg = load_config()
    engine = make_engine(cfg)
    bootstrap_raw(engine)
    bootstrap_mart(engine)  # —Å–æ–∑–¥–∞–¥–∏–º —Å—Ö–µ–º—É mart –∏ —Ç–∞–±–ª–∏—Ü—É, –µ—Å–ª–∏ –∏—Ö –µ—â—ë –Ω–µ—Ç


    log_id = start_log(engine, source="ozon", endpoint="/v2/analytics/stock_on_warehouses")
    try:
        print("üöÄ –ó–∞–ø—É—Å–∫ ETL –∏–∑ Ozon API...")
        items = fetch_all_ozon_stock(cfg, page_limit=1000)
        print(f"–ü–æ–ª—É—á–µ–Ω–æ –≤—Å–µ–≥–æ: {len(items)}")

        df_norm = normalize_stock(items)
        rows_raw = rows_norm = 0
        if not args.dry_run:
            rebuild_mart_from_raw(engine)


        if not args.dry_run:
            rows_raw = persist_raw(engine, items)
            rows_norm = persist_normalized(engine, df_norm)

        finish_log(engine, log_id, status="ok", rows=rows_norm, message=f"raw={rows_raw}, norm={rows_norm}")
        print(f"‚úÖ –ó–∞–ø–∏—Å–∞–Ω–æ –≤ raw: {rows_raw}, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {rows_norm}")
    except Exception as e:
        finish_log(engine, log_id, status="error", rows=0, message=str(e))
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        raise

if __name__ == "__main__":
    run()
